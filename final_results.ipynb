{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Novel Approaches to Predict Yelp Ratings\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "In our research we explore two novel methods for predicting user ratings on the domain of Yelp businesses. We provide a prospective business advertiser/marketer/researcher a detailed comparison of the differences between methods and suggest practical considerations for their usage.\n",
    "\n",
    "Keywords: Machine Learning; Collaborative Filtering; Ensemble Models; Factorization Machines\n",
    "\n",
    "#### Contributors:\n",
    "- EK Itoku | UNI: ii2155 | Email: ii2155@columbia.edu\n",
    "- Jason Kuo | UNI: jk4097 | Email: jk4097@columbia.edu\n",
    "- Sean Xu | UNI: cx2118 | Email: cx2118@columbia.edu\n",
    "\n",
    "\n",
    "#### Report Layout:\n",
    "\n",
    "* Objectives\n",
    "* Data Extraction and Feature Engineering\n",
    "* Evaluation Metrics\n",
    "* Recommendation Approaches and Analysis of Results\n",
    "    + Accuracy Across User Distributions\n",
    "    + Accuracy Across Restaurant Distributions\n",
    "    + Recommendation Coverage\n",
    "* Implementation Considerations\n",
    "* Conclusions and Takeaways\n",
    "* References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from source.utils import plot_lines, create_quantile_bucket, rmse, calculate_catalog_coverage\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = \"{:4.2f}\".format\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this study we aim to predict the rating of the last business a Yelp user visits. A rating is on the scale of 1 - 5 with 5 representing great. For marketing companies, this can be invaluable in identifying potential users who will like a targeted business and only focus advertising to those users with high predicted ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Feature Engineering\n",
    "Yelp has generously provided a rich amount of information on the reviews on its site to academic researchers. We decided to utilize the business and user data in addition to the reviews file in hopes of enriching the model with contextual information to improve rating predictions.\n",
    "\n",
    "After performing exploratory data analysis on the business file, we decided to focus solely on restaurants as it was the main business category and what we believe most users come to the site to solicit recommendations on. Yelp provides a multi-label category classification of each business of which we applied a filter to detect businesses with a ‘restaurant’ label as one of its categories. From there we one-hot-encoded the accompanying categories such as type of cuisine and whether it was also considered a bar by keeping the categories that show up in at least 1% of the data. We also identified non-US businesses by observing alphanumeric zip codes such as those in Canada. We decided to focus on the US market by filtering for US-zip code patterns as the international data collected and real-world usage was limited. We removed any businesses marked as closed in order to train the model to generate potential recommendations drawing from currently available establishments. Finally, we set a minimum of 50 reviews for a business ensure a sufficient amount of data to properly learn from our users.\n",
    "\n",
    "Looking into the users file, we applied a similar filter of keeping users with at least 5 reviews to draw experience from. We constructed a few features such as total user compliments, number of elite year status and how many years Yelping in order to better fit into our models.\n",
    "The reviews file we took mostly as default aside from seeing if the number of props (‘useful’, ‘funny’, ‘cool’ likes) on the given review impacted the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "To achieve our objective, we used two different evaluation schemes:\n",
    "\n",
    "\n",
    "#### - Root Mean Squared Error (Primary Benchmark)\n",
    "\n",
    "We use the root mean squared error benchmark (RMSE) to measure the deviation of our predicted rating from the true rating in our testing set. A lower result is better signaling less prediction error.\n",
    "\n",
    "\n",
    "#### - Mean Absolute Error (Secondary Benchmark)\n",
    "\n",
    "RMSE penalizes the larger deviations from the true rating more than similarly spaced apart smaller deviations when the total amount of deviation is the same. Mean Absolute Error (MAE) measures all deviations similarly. \n",
    "\n",
    "\n",
    "#### - Coverage Metric\n",
    "To estimate recommendation coverage, we decided to recommend the top 20 restaurants for a user by predicted rating and compare the universe of recommendations of all users vs. the total amount of establishments. Due to the sheer number of users in our dataset (>235k unique profiles) and the number of restaurants to predict against (>11k) we decided to sample 5k users as a representative set to manage prediction time. While not as ideal as using the entire dataset, by applying the same methodology across all our models we can compare and contrast their differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Approaches and Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Baseline (Bias Model)\n",
    "<img src=\"image/baseline1.png\" alt=\"drawing\" width=\"200\"/>\n",
    "Where we adjust the mean rating of all users and all items by the observed deviations of user u and item i.\n",
    "\n",
    "In order to avoid overfitting, we add regularizations by penalizing the magnitudes of the parameters.\n",
    "<img src=\"image/baseline2.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "In Surprise implementation, for easier calculation, it decouples the calculation of b_u and b_i. For b_i\n",
    "<img src=\"image/baseline3.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "For b_u\n",
    "<img src=\"image/baseline4.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "And Surprise provides two algorithms to calculate the parameters: Baselines can be estimated in two different ways:\n",
    "Stochastic Gradient Descent (SGD)\n",
    "Alternating Least Squares (ALS)\n",
    "\n",
    "We run a GridSearch for both algorithms on accuracy matrix including:\n",
    "- Primary: RMSE\n",
    "- Secondary: MAE\n",
    "\n",
    "Results:\n",
    "\n",
    "\n",
    "\n",
    "Algorithm | Model with least RMSE | RMSE | Model with least MAE | MAE\n",
    "----------|-----------------------|------|----------------------|----\n",
    "ALS|'n_epochs': 30, 'reg_u': 10, 'reg_i': 10|1.15|'n_epochs': 30, 'reg_u': 10, 'reg_i': 10 |0.92\n",
    "SGD|'n_epochs': 30, 'reg': 0.1, 'learning_rate': 0.005|1.15|'n_epochs': 30, 'reg': 0.01, 'learning_rate': 0.01|0.90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Individual and Ensemble Methods\n",
    "\n",
    "#### Individual models\n",
    "We considered several models individually and then ensembling them including:\n",
    "- baselineonly\n",
    "- KNN(Basic and With_Means)\n",
    "- SVD\n",
    "- co-colustering\n",
    "\n",
    "#### - KNN\n",
    "The idea is to use similar users or items to predict the rating of given user and item. \n",
    "\n",
    "<img src=\"image/knn1.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<img src=\"image/knn2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "There are several ways to calculate the similarities including cosine, pearson and msd.\n",
    "\n",
    "The hyperparameter tuning results are:\n",
    "\n",
    "\n",
    "Algorithm|Model with least RMSE|RMSE|Model with least MAE|MAE\n",
    "---------|---------------------|----|--------------------|---\n",
    "KNNBasic|‘similarity_method’: cosine, 'k': 40|1.50|‘similarity_method’: msd, 'k': 20|1.12\n",
    "KNNwithMean|‘similarity_method’: cosine, 'k': 40|1.39|‘similarity_method’: cosine, 'k': 40|1.05\n",
    "\n",
    "#### - SVD\n",
    "A matrix factorization method which is popularized by Simon Funk during the Netflix Prize. When baselines are not used, this is equivalent to Probabilistic Matrix Factorization. \n",
    "\n",
    "Model with least RMSE|RMSE|Model with least MAE|MAE\n",
    "---------------------|----|--------------------|---\n",
    "'n_factors': 50, 'lr_all': 0.005, 'reg_all': 0.1|1.13|'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0.1|0.89\n",
    "\n",
    "\n",
    "#### - Co-Clustering\n",
    "\n",
    "Cluster assignments are done by basic techniques like kmeans.\n",
    "\n",
    "<img src=\"image/cocluster.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "#### Ensemble\n",
    "\n",
    "The idea of ensemble model is to stack a set of basic recommendation models and use the weighted sum of the predictions as the new prediction which ideally will remove the flaws in individual implementation.\n",
    "- Averaging\n",
    "- Weighted Average (Train weights with linear regression and ElasticNet regression)\n",
    "\n",
    "Steps:\n",
    "1. Tune the hyperparameter of base models including:\n",
    "2. Train base models using the tuned hyperparameters\n",
    "3. Run regression to learn the weights or simply use average\n",
    "4. Stack models together with weights (average or trained weights)\n",
    "\n",
    "Results:\n",
    "\n",
    "\n",
    "Model | RMSE\n",
    "------|-----\n",
    "Base Models|1.13 - 1.33\n",
    "Ensemble with average weights|1.32\n",
    "Ensemble with weights learned from linear regression|1.32\n",
    "Ensemble with weights learned from ElasticNet|1.39\n",
    "\n",
    "Model | MAE\n",
    "------|----\n",
    "Base Models|0.9 - 1\n",
    "Ensemble with average weights|1.05\n",
    "Ensemble with weights learned from linear regression|1.03\n",
    "Ensemble with weights learned from ElasticNet|1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Factorization Machines\n",
    "\n",
    "Factorization Machines are a state of the art solution to recommendation problems. In theory, FMs should produce better results than MF due to interaction terms but in practice it might not necessary be the case. If side information is omitted, then FMs become the same as the MF model.\n",
    "\n",
    "FMs are similar to collective approaches allowing for multiple relationships between entities but differ in:\n",
    "- FMs use a clever feature representation to cast factorization as a regression, classification, or ranking problem\n",
    "- In addition to relations between entities, FMs allow for interaction terms for items within a single entity type\n",
    "- FMs can be defined such that they act like, or mimic, other techniques like SVD++\n",
    "\n",
    "In addition to hyperparameter tuning, we have tested various configurations of the feature set.\n",
    "\n",
    "Results:\n",
    "\n",
    "Algorithm | Model Parameters | Model Features | RMSE | MAE\n",
    "----------|-----------------------|------|----------------------|----\n",
    "FM|'task':'reg', 'lr':0.5,'lambda':0, 'metric':'rmse', 'k':20, 'epoch':20| 'user_id', 'business_id', 'user_review_count', 'user_elite', 'user_fans', 'user_average_stars', 'user_compliment', 'user_yelping_years' + OHE Restaurant Categories |1.257405 | 1.011706\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your models work equally well for all users?\n",
    "\n",
    "We will evaluate models from two different angles:\n",
    "##### 1. In terms of number of ratings users provided\n",
    "The more users review restaurants, the better our predictions perform. This is intuitive as there are more samples models to learn, we can train models better. The baseline model was superior across most models but FM was notable that it was able to provide resonable prediction accuracy for users with fewer ratings.\n",
    "\n",
    "\n",
    "##### 2. In terms of attaining elite status\n",
    "Our experiments show that our models perform better for elite users. For example, MAE is 0.78 for elite users whereas 1.03 for non-elite users. We think this is because there are more samples for elite users. Another possibility is that there might be some spam users or malicious business accounts that rate restaurants in an unusual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"user_id\",\n",
    "    \"business_id\",\n",
    "    \"review_stars\",\n",
    "    \"user_average_stars\",\n",
    "    \"user_review_count\",\n",
    "    \"user_elite\",\n",
    "    \"user_fans\",\n",
    "    \"business_stars\",\n",
    "    \"business_review_count\",\n",
    "]\n",
    "truth = pd.read_csv(\"data/feature.csv\", usecols=cols)\n",
    "all_businesses = truth.business_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_result_files = [\n",
    "    \"baseline_pred.pkl\",\n",
    "    \"knnwithmeans_pred.pkl\",\n",
    "    \"svd_pred.pkl\",\n",
    "    \"coclustering_pred.pkl\",\n",
    "    \"knnbasic_pred.pkl\",\n",
    "    \"ensemble_pred.pkl\",\n",
    "    \"fm_pred.pkl\",\n",
    "]\n",
    "preds = []\n",
    "\n",
    "for fn in model_result_files:\n",
    "    pred = pd.read_pickle(f\"result/{fn}\")\n",
    "    pred = pred.merge(truth, on=[\"user_id\", \"business_id\"], how=\"inner\")\n",
    "\n",
    "    pred[\"squared_error\"] = (pred.review_stars - pred.y_pred) ** 2\n",
    "    pred[\"absolute_error\"] = (pred.review_stars - pred.y_pred).abs()\n",
    "\n",
    "    preds.append([fn.split(\"_\")[0], pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.12 0.81 0.00 0.51 0.95 1.59 4.00\n",
      "(7.0, 9.0]            24570.00  1.10 0.82 0.00 0.46 0.92 1.56 4.00\n",
      "(9.0, 11.0]           20224.00  1.07 0.80 0.00 0.45 0.90 1.52 4.00\n",
      "(11.0, 14.0]          23186.00  1.04 0.79 0.00 0.43 0.87 1.49 4.00\n",
      "(14.0, 18.0]          22003.00  1.02 0.79 0.00 0.42 0.86 1.45 4.00\n",
      "(18.0, 25.0]          24238.00  1.01 0.79 0.00 0.39 0.84 1.45 4.00\n",
      "(25.0, 38.0]          23846.00  0.98 0.78 0.00 0.38 0.81 1.40 4.00\n",
      "(38.0, 68.0]          24415.00  0.93 0.75 0.00 0.36 0.77 1.31 4.00\n",
      "(68.0, 161.0]         24665.00  0.88 0.70 0.00 0.35 0.72 1.23 4.00\n",
      "(161.0, 13278.0]      24647.00  0.79 0.63 0.00 0.31 0.66 1.10 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.18 1.02 0.00 0.30 1.04 1.78 4.00\n",
      "(7.0, 9.0]            24570.00  1.14 1.01 0.00 0.30 1.00 1.72 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 0.97 0.00 0.29 0.93 1.61 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.95 0.00 0.29 0.89 1.58 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.92 0.00 0.30 0.85 1.53 4.00\n",
      "(18.0, 25.0]          24238.00  1.04 0.90 0.00 0.31 0.84 1.51 4.00\n",
      "(25.0, 38.0]          23846.00  1.00 0.86 0.00 0.32 0.82 1.44 4.00\n",
      "(38.0, 68.0]          24415.00  0.96 0.82 0.00 0.32 0.78 1.35 4.00\n",
      "(68.0, 161.0]         24665.00  0.91 0.77 0.00 0.31 0.74 1.26 4.00\n",
      "(161.0, 13278.0]      24647.00  0.82 0.69 0.00 0.30 0.68 1.16 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.14 0.78 0.00 0.55 0.97 1.56 4.00\n",
      "(7.0, 9.0]            24570.00  1.12 0.79 0.00 0.52 0.95 1.54 4.00\n",
      "(9.0, 11.0]           20224.00  1.08 0.77 0.00 0.50 0.91 1.48 4.00\n",
      "(11.0, 14.0]          23186.00  1.06 0.77 0.00 0.48 0.89 1.47 4.00\n",
      "(14.0, 18.0]          22003.00  1.04 0.77 0.00 0.46 0.87 1.43 4.00\n",
      "(18.0, 25.0]          24238.00  1.01 0.77 0.00 0.43 0.84 1.42 4.00\n",
      "(25.0, 38.0]          23846.00  0.98 0.76 0.00 0.41 0.81 1.36 4.00\n",
      "(38.0, 68.0]          24415.00  0.93 0.73 0.00 0.38 0.77 1.28 4.00\n",
      "(68.0, 161.0]         24665.00  0.87 0.68 0.00 0.36 0.73 1.20 4.00\n",
      "(161.0, 13278.0]      24647.00  0.78 0.62 0.00 0.31 0.66 1.08 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.18 1.08 0.00 0.20 1.01 1.84 4.00\n",
      "(7.0, 9.0]            24570.00  1.15 1.05 0.00 0.21 1.00 1.76 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 1.02 0.00 0.22 0.92 1.66 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.99 0.00 0.24 0.89 1.62 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.95 0.00 0.26 0.85 1.57 4.00\n",
      "(18.0, 25.0]          24238.00  1.03 0.92 0.00 0.28 0.84 1.53 4.00\n",
      "(25.0, 38.0]          23846.00  1.00 0.89 0.00 0.29 0.81 1.47 4.00\n",
      "(38.0, 68.0]          24415.00  0.96 0.84 0.00 0.30 0.79 1.39 4.00\n",
      "(68.0, 161.0]         24665.00  0.92 0.79 0.00 0.31 0.75 1.30 4.00\n",
      "(161.0, 13278.0]      24647.00  0.85 0.71 0.00 0.30 0.70 1.19 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.24 1.13 0.00 0.16 1.16 1.98 4.00\n",
      "(7.0, 9.0]            24570.00  1.23 1.11 0.00 0.24 1.00 1.95 4.00\n",
      "(9.0, 11.0]           20224.00  1.17 1.07 0.00 0.21 1.00 1.84 4.00\n",
      "(11.0, 14.0]          23186.00  1.16 1.05 0.00 0.28 1.00 1.77 4.00\n",
      "(14.0, 18.0]          22003.00  1.13 1.00 0.00 0.33 1.00 1.69 4.00\n",
      "(18.0, 25.0]          24238.00  1.12 0.97 0.00 0.34 0.99 1.66 4.00\n",
      "(25.0, 38.0]          23846.00  1.09 0.92 0.00 0.38 0.97 1.52 4.00\n",
      "(38.0, 68.0]          24415.00  1.03 0.86 0.00 0.36 0.91 1.45 4.00\n",
      "(68.0, 161.0]         24665.00  0.97 0.81 0.00 0.34 0.85 1.33 4.00\n",
      "(161.0, 13278.0]      24647.00  0.90 0.74 0.00 0.33 0.79 1.22 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.17 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(7.0, 9.0]            24570.00  1.14 0.86 0.00 0.50 1.00 1.50 4.00\n",
      "(9.0, 11.0]           20224.00  1.10 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(11.0, 14.0]          23186.00  1.08 0.84 0.00 0.50 1.00 1.50 4.00\n",
      "(14.0, 18.0]          22003.00  1.05 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(18.0, 25.0]          24238.00  1.03 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(25.0, 38.0]          23846.00  0.99 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(38.0, 68.0]          24415.00  0.94 0.79 0.00 0.50 1.00 1.50 4.00\n",
      "(68.0, 161.0]         24665.00  0.88 0.74 0.00 0.50 0.50 1.00 4.00\n",
      "(161.0, 13278.0]      24647.00  0.80 0.68 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "                         count  mean  std  min  25%  50%  75%  max\n",
      "user_review_count_bin                                             \n",
      "(4.999, 7.0]          35329.00  1.03 0.84 0.00 0.37 0.81 1.50 5.73\n",
      "(7.0, 9.0]            24570.00  1.01 0.78 0.00 0.39 0.84 1.48 4.32\n",
      "(9.0, 11.0]           20224.00  1.02 0.75 0.00 0.42 0.87 1.46 4.41\n",
      "(11.0, 14.0]          23186.00  1.02 0.75 0.00 0.43 0.87 1.43 4.18\n",
      "(14.0, 18.0]          22003.00  1.03 0.75 0.00 0.46 0.87 1.44 4.08\n",
      "(18.0, 25.0]          24238.00  1.05 0.76 0.00 0.49 0.90 1.41 3.99\n",
      "(25.0, 38.0]          23846.00  1.05 0.73 0.00 0.55 0.94 1.34 3.62\n",
      "(38.0, 68.0]          24415.00  1.03 0.70 0.00 0.52 1.00 1.29 3.67\n",
      "(68.0, 161.0]         24665.00  0.98 0.68 0.00 0.36 1.02 1.28 3.50\n",
      "(161.0, 13278.0]      24647.00  0.89 0.64 0.00 0.28 0.80 1.25 3.35\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. In terms of number of ratings users provided\n",
    "for nm, pred in preds:\n",
    "    pred[\"user_review_count_bin\"] = pd.qcut(pred.user_review_count, 10)\n",
    "    desc = pred.groupby(\"user_review_count_bin\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.03 0.79 0.00 0.42 0.86 1.47 4.00\n",
      "True        33842.00  0.78 0.63 0.00 0.31 0.64 1.09 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.07 0.93 0.00 0.31 0.88 1.54 4.00\n",
      "True        33842.00  0.81 0.69 0.00 0.29 0.66 1.15 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.04 0.77 0.00 0.46 0.87 1.44 4.00\n",
      "True        33842.00  0.77 0.62 0.00 0.31 0.65 1.07 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.07 0.97 0.00 0.26 0.88 1.57 4.00\n",
      "True        33842.00  0.83 0.71 0.00 0.29 0.68 1.16 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.14 1.01 0.00 0.33 1.00 1.69 4.00\n",
      "True        33842.00  0.88 0.74 0.00 0.32 0.76 1.17 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.06 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "True        33842.00  0.79 0.68 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "               count  mean  std  min  25%  50%  75%  max\n",
      "user_elite                                              \n",
      "False      213281.00  1.04 0.76 0.00 0.44 0.91 1.41 5.73\n",
      "True        33842.00  0.85 0.64 0.00 0.24 0.84 1.19 3.52\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. In terms of number of elite status\n",
    "\n",
    "for nm, pred in preds:\n",
    "    pred.user_elite = pred.user_elite > 0\n",
    "    desc = pred.groupby(\"user_elite\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your models work equally well for all restaurants?\n",
    "\n",
    "Our models perform better for the restaurants that are popular with more reviews. Similar to the user analysis above, the models perform better if there are more data to learn patterns on which is highly intuitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.10 0.80 0.00 0.47 0.96 1.59 4.00\n",
      "(84.0, 125.0]             24420.00  1.05 0.78 0.00 0.44 0.89 1.50 4.00\n",
      "(125.0, 173.0]            25025.00  1.06 0.78 0.00 0.44 0.90 1.52 4.00\n",
      "(173.0, 236.0]            24782.00  1.03 0.78 0.00 0.43 0.86 1.47 4.00\n",
      "(236.0, 313.0]            24431.00  1.02 0.79 0.00 0.41 0.84 1.45 4.00\n",
      "(313.0, 413.0]            24706.00  1.00 0.78 0.00 0.41 0.83 1.40 4.00\n",
      "(413.0, 555.0]            24662.00  0.98 0.77 0.00 0.39 0.80 1.37 4.00\n",
      "(555.0, 851.0]            24650.00  0.97 0.77 0.00 0.38 0.78 1.35 4.00\n",
      "(851.0, 1476.0]           24765.00  0.90 0.75 0.00 0.36 0.72 1.22 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.87 0.71 0.00 0.34 0.72 1.19 4.00\n",
      "\n",
      "\n",
      "knnwithmeans\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.14 0.95 0.00 0.36 0.96 1.69 4.00\n",
      "(84.0, 125.0]             24420.00  1.08 0.92 0.00 0.34 0.89 1.56 4.00\n",
      "(125.0, 173.0]            25025.00  1.09 0.93 0.00 0.33 0.91 1.60 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.92 0.00 0.32 0.86 1.52 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.92 0.00 0.30 0.85 1.50 4.00\n",
      "(313.0, 413.0]            24706.00  1.03 0.91 0.00 0.30 0.84 1.44 4.00\n",
      "(413.0, 555.0]            24662.00  1.01 0.90 0.00 0.29 0.83 1.43 4.00\n",
      "(555.0, 851.0]            24650.00  1.00 0.89 0.00 0.30 0.82 1.39 4.00\n",
      "(851.0, 1476.0]           24765.00  0.94 0.86 0.00 0.26 0.75 1.27 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.92 0.81 0.00 0.27 0.75 1.26 4.00\n",
      "\n",
      "\n",
      "svd\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.11 0.77 0.00 0.50 0.97 1.59 4.00\n",
      "(84.0, 125.0]             24420.00  1.06 0.77 0.00 0.47 0.90 1.49 3.98\n",
      "(125.0, 173.0]            25025.00  1.06 0.76 0.00 0.47 0.91 1.49 4.00\n",
      "(173.0, 236.0]            24782.00  1.03 0.76 0.00 0.45 0.88 1.44 4.00\n",
      "(236.0, 313.0]            24431.00  1.03 0.77 0.00 0.45 0.86 1.42 4.00\n",
      "(313.0, 413.0]            24706.00  1.01 0.76 0.00 0.44 0.84 1.36 4.00\n",
      "(413.0, 555.0]            24662.00  0.99 0.75 0.00 0.43 0.82 1.34 4.00\n",
      "(555.0, 851.0]            24650.00  0.97 0.75 0.00 0.42 0.81 1.30 4.00\n",
      "(851.0, 1476.0]           24765.00  0.91 0.72 0.00 0.39 0.74 1.19 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.87 0.69 0.00 0.35 0.73 1.16 4.00\n",
      "\n",
      "\n",
      "coclustering\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.13 0.99 0.00 0.31 0.95 1.72 4.00\n",
      "(84.0, 125.0]             24420.00  1.07 0.95 0.00 0.29 0.89 1.57 4.00\n",
      "(125.0, 173.0]            25025.00  1.09 0.97 0.00 0.28 0.90 1.61 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.96 0.00 0.27 0.87 1.56 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.96 0.00 0.26 0.86 1.55 4.00\n",
      "(313.0, 413.0]            24706.00  1.04 0.95 0.00 0.25 0.84 1.48 4.00\n",
      "(413.0, 555.0]            24662.00  1.02 0.94 0.00 0.25 0.83 1.47 4.00\n",
      "(555.0, 851.0]            24650.00  1.01 0.93 0.00 0.26 0.83 1.45 4.00\n",
      "(851.0, 1476.0]           24765.00  0.95 0.90 0.00 0.22 0.76 1.31 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.94 0.85 0.00 0.26 0.78 1.31 4.00\n",
      "\n",
      "\n",
      "knnbasic\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.25 1.07 0.00 0.34 1.00 1.96 4.00\n",
      "(84.0, 125.0]             24420.00  1.17 1.02 0.00 0.33 1.00 1.75 4.00\n",
      "(125.0, 173.0]            25025.00  1.17 1.03 0.00 0.33 1.00 1.76 4.00\n",
      "(173.0, 236.0]            24782.00  1.13 1.01 0.00 0.32 1.00 1.66 4.00\n",
      "(236.0, 313.0]            24431.00  1.12 1.00 0.00 0.31 1.00 1.63 4.00\n",
      "(313.0, 413.0]            24706.00  1.09 0.98 0.00 0.30 1.00 1.51 4.00\n",
      "(413.0, 555.0]            24662.00  1.09 0.97 0.00 0.32 1.00 1.52 4.00\n",
      "(555.0, 851.0]            24650.00  1.06 0.95 0.00 0.32 0.98 1.49 4.00\n",
      "(851.0, 1476.0]           24765.00  1.02 0.91 0.00 0.32 0.92 1.40 4.00\n",
      "(1476.0, 8348.0]          24647.00  1.00 0.87 0.00 0.33 0.93 1.37 4.00\n",
      "\n",
      "\n",
      "ensemble\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.14 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(84.0, 125.0]             24420.00  1.08 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(125.0, 173.0]            25025.00  1.08 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(173.0, 236.0]            24782.00  1.06 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(236.0, 313.0]            24431.00  1.05 0.83 0.00 0.50 1.00 1.50 4.00\n",
      "(313.0, 413.0]            24706.00  1.02 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(413.0, 555.0]            24662.00  1.00 0.82 0.00 0.50 1.00 1.50 4.00\n",
      "(555.0, 851.0]            24650.00  0.99 0.81 0.00 0.50 1.00 1.50 4.00\n",
      "(851.0, 1476.0]           24765.00  0.92 0.80 0.00 0.50 1.00 1.00 4.00\n",
      "(1476.0, 8348.0]          24647.00  0.88 0.76 0.00 0.50 0.50 1.00 4.00\n",
      "\n",
      "\n",
      "fm\n",
      "                             count  mean  std  min  25%  50%  75%  max\n",
      "business_review_count_bin                                             \n",
      "(49.999, 84.0]            25035.00  1.12 0.78 0.00 0.50 1.00 1.57 5.28\n",
      "(84.0, 125.0]             24420.00  1.06 0.76 0.00 0.45 0.95 1.46 4.78\n",
      "(125.0, 173.0]            25025.00  1.05 0.76 0.00 0.45 0.93 1.44 5.73\n",
      "(173.0, 236.0]            24782.00  1.03 0.75 0.00 0.44 0.91 1.41 5.59\n",
      "(236.0, 313.0]            24431.00  1.03 0.76 0.00 0.42 0.90 1.39 5.54\n",
      "(313.0, 413.0]            24706.00  1.01 0.75 0.00 0.41 0.89 1.34 4.64\n",
      "(413.0, 555.0]            24662.00  0.99 0.74 0.00 0.40 0.87 1.32 5.40\n",
      "(555.0, 851.0]            24650.00  0.98 0.74 0.00 0.38 0.87 1.30 4.61\n",
      "(851.0, 1476.0]           24765.00  0.94 0.71 0.00 0.36 0.84 1.25 5.30\n",
      "(1476.0, 8348.0]          24647.00  0.92 0.68 0.00 0.34 0.83 1.25 4.52\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nm, pred in preds:\n",
    "    pred[\"business_review_count_bin\"] = pd.qcut(pred.business_review_count, 10)\n",
    "    desc = pred.groupby(\"business_review_count_bin\").absolute_error.describe()\n",
    "    print(nm)\n",
    "    print(desc)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_top_20.pkl', 'fm_top_20.pkl', 'knnbasic_top_20.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE SHOULD DELETE THIS BEFORE SUBMIT\n",
    "[fn for fn in os.listdir(\"result\") if fn.endswith(\"_top_20.pkl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.2171305826546138\n",
      "knnbasic 0.9983889734180614\n",
      "fm 0.008234135863241744\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    'baseline_top_20.pkl', \n",
    "    'knnbasic_top_20.pkl',\n",
    "    'fm_top_20.pkl',\n",
    "]\n",
    "\n",
    "for fn in file_names:\n",
    "    pred = pd.read_pickle(f\"result/{fn}\")\n",
    "    coverage = calculate_catalog_coverage(all_businesses, pred)\n",
    "    print(fn.split(\"_\")[0] , coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage scores for the models were across the board for the models, with KNN having an extremely high score and FM being extremely low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Considerations\n",
    "\n",
    "For Yelp or any other resturant recommendation business looking to employ one of these methods into real-world use, they should consider the following:\n",
    "\n",
    "#### New Users\n",
    "\n",
    "With no existing data, it is question on how to provide an appropriate recommendation for new users. One suggestion is to factor elite user's recommendations more heavily that non-elites as the model has learned to predict better on the expected rating of experts. Identifying the top 20 nearest elites to the user and taking their highest average recommended score of resturants can prove to be a more reliable recommendation. In addition, factorization machines appear to have promise in generalizing user preferences better than baseline bias models for less active years.\n",
    "\n",
    "\n",
    "#### Model Complexity\n",
    "\n",
    "As shown through our results, a properly set up simple bias model can provide great results with less implementation risk than a more complicated model with varying degrees of improvement. Yelp may favor simplifying the processing pipeline in order to avoid having to make too many assumptions in more sophisticated feature engineering.\n",
    "\n",
    "\n",
    "#### Recommendation Diversity\n",
    "\n",
    "Recommendation diversity, as measured by our coverage metric, can be a notable consideration. Yelp could favor a high level of coverage across their catalogue to highlight the diversity of their platform. If they could recommend more hole-in-the-wall or niche restaurants while providing high levels of user engagement then they could convince smaller establishments to pay for more targeted advertising with the premise of being more likely shown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Takeaways\n",
    "\n",
    "In conclusion, we have shown a variety of ML-based approaches are effective at providing resturant rating predictions for users with a varying amount of previous recommendation history. While it was difficult to beat our baseline recommender using a bias model, we have seen that contextual information has promise in improving prediction accuracy for less active users. We provided practical implementation considerations for Yelp to adopt and expand on our approaches. We have also developed an end-to-end pipeline from data extraction to built models for Yelp to explore. \n",
    "\n",
    "Looking forward, the researchers would like to continue to investigate the impact of incorporating additional features to supplement the predictions of users with fewer ratings. Prospective areas to explore include factoring local geography of the resturants, identifying local experts who can influence other users more strongly via a relational network or running NLP on the review texts to understand personal preferences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1: https://towardsdatascience.com/precision-vs-recall-386cf9f89488\n",
    "\n",
    "2: https://surprise.readthedocs.io/en/stable/index.html\n",
    "\n",
    "3: https://xlearn-doc.readthedocs.io/en/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
